---
title: 'Machine Learning, Lab 4: Deep Learning'
author: "Scout Leonard"
date: "2/23/2022"
output:
  prettydoc::html_pretty:
      theme: cayman
  toc: true
  toc_float: true
  code_folding: show
  theme: flat
---

# Load Libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)

librarian::shelf("tensorflow",
                 "keras",
                 "dplyr",
                 "shelf",
                 "digest",
                 "tidyverse")

# install Python into user space
(reticulate::miniconda_path()) # show the Python path
if (!file.exists(reticulate::miniconda_path()))
  reticulate::install_miniconda()

# install keras with tensorflow
if (!keras::is_keras_available())
  keras::install_keras()
```

# Assignment Overview, Background, and Objectives

## Deep Learning with R / Python Exercises

You'll first learn about Computer Vision techniques by going through the Chapter 5 lab exercises:

- 5.1 Introduction to convnets
  R: [html](./lab4c_5.1.intro-convnets.html), [Rmd](https://raw.githubusercontent.com/bbest/eds232-ml/main/lab4c_5.1.intro-convnets.Rmd) ; Python: [html](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.2-using-convnets-with-small-datasets.ipynb), [ipynb](https://raw.githubusercontent.com/fchollet/deep-learning-with-python-notebooks/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.2-using-convnets-with-small-datasets.ipynb)

- 5.2 Training a convnet from scratch on a small dataset
  R: [html](./lab4c_5.2.small-convnets.html), [Rmd](https://raw.githubusercontent.com/bbest/eds232-ml/main/lab4c_5.2.small-convnets.Rmd) ; Python: [html](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.1-introduction-to-convnets.ipynb), [ipynb](https://raw.githubusercontent.com/fchollet/deep-learning-with-python-notebooks/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.1-introduction-to-convnets.ipynb)

The subsequent lab exercises meet the limits of using a CPU over a GPU, which is not available on `taylor.bren.ucsb.edu`. Here's as far as I was able to get for demonstration sake, but you're not expected to run this. You might want to try if you have personal computer with a GPU setup.

- 5.3 Using a pretrained convnet
  R: [html](./lab4c_5.3-using-a-pretrained-convnet.html), [Rmd](https://raw.githubusercontent.com/bbest/eds232-ml/main/lab4c_5.3-using-a-pretrained-convnet.Rmd) ; Python: [html](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.3-using-a-pretrained-convnet.ipynb), [ipynb](https://raw.githubusercontent.com/fchollet/deep-learning-with-python-notebooks/8a30b90fed187aaddaaf1fc868ec8e0ac92bca40/5.3-using-a-pretrained-convnet.ipynb)

## iNaturalist

The main lab that you'll turn in is to apply these techniques to a small subset of the iNaturalist species imagery. These data were downloaded from the links provided at [github.com/visipedia/inat_comp:2021/](https://github.com/visipedia/inat_comp/tree/master/2021). Of all the 10,000 species and many images for each from training (Train), training mini (Train Mini), validation (Val) and test images, you'll draw only from the Train Mini set of images:

![](https://github.com/visipedia/inat_comp/raw/master/2021/assets/train_val_distribution.png)

# 2 Species Pre-Processing of Images

```{r}
# path to folder containing species directories of images
dir_train_mini <- "/courses/EDS232/inaturalist-2021/train_mini"

# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_train_mini, recursive = F)
n_spp <- length(dirs_spp)

# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% 
  digest::digest2int() %>% 
  set.seed()

# show the 10 indices sampled of the 10,000 possible 
i10 <- sample(1:n_spp, 10)
i10
species_10 <- basename(dirs_spp)[i10]

# show the first 2 species directory names
i2 <- i10[1:2]
i2
species_2 <- basename(dirs_spp)[i2]
```

```{r}
#create base file paths
base_dir <- "/Users/scout/EDS232/eds232_lab4/lab_4c_deep_learning"
train_2_dir <- file.path(base_dir, "train_2")
validation_2_dir <- file.path(base_dir, "validation_2")
test_2_dir <- file.path(base_dir, "test_2")

# create base folders
dir.create(train_2_dir)
dir.create(validation_2_dir)
dir.create(test_2_dir)

#create folder for each species
for (i in 1:length(species_2)){
  dir.create(file.path(train_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
  dir.create(file.path(validation_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
  dir.create(file.path(test_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
}
```

```{r}
# create test, validation, and training groups of images for both species
for(i in 1:length(species_2)){
  # create 5 groups of 10 random samples
  species_samples_2 <- replicate(5, 
                                  sample(list.files(paste0(dir_train_mini, "/", species_2[[i]]), 
                                                    full.names = TRUE), replace = FALSE, 10))
  ## train n = 30 ##
  train <- rbind(species_samples_2[,1], species_samples_2[,2], species_samples_2[,3])
  file.copy(from = train, 
            to = paste0(train_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
  ## validation n = 10 ##
  validate <- species_samples_2[,4]
  file.copy(from = validate,
            to = paste0(validation_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
  ## train n = 10 ##
  test <- species_samples_2[,5]
  file.copy(from = test,
            to = paste0(test_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
  }
```

```{r}
# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)
test_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  # This is the target directory
  train_2_dir,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 5,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary")

validation_generator <- flow_images_from_directory(
  validation_2_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "binary")

test_generator <- flow_images_from_directory(
  test_2_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "binary")
```

```{r}
batch <- generator_next(train_generator)
str(batch)
```

# Apply Images to Binary Classification Deep Learning Models

## Binary Classification: Neural Net

1. **2 Species (binary classification) - neural net**. Draw from [3.4 🍿 Movies (binary classification)](./lab4b_examples.html). You'll need to pre-process the images to be a consistent shape first though -- see 5.2.4 Data preprocessing.

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_flatten() %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "sigmoid")
```

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))
```

```{r}
history <- model %>% fit(
    train_generator,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = 5)
```

```{r}
plot(history)
```

```{r}
history
```

```{r}
test_generator <- flow_images_from_directory(
  test_2_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "binary"
)

model %>% evaluate_generator(test_generator, steps = 50)
```

## Binary Classification: Covolutional Neural Net

2. **2 Species (binary classification) - convolutional neural net**. Draw from the [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html).

```{r}
# write the model 
model <- keras_model_sequential() %>% 
  layer_conv_2d(
    filters = 32, kernel_size = c(3, 3), activation = "relu",
    input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")  
  
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc"))
```

```{r}
history_2 <- model %>% fit(
    train_generator,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = 5)
```

```{r}
history_2
```

```{r}
test_generator_2 <- flow_images_from_directory(
  test_2_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
model %>% evaluate(test_generator_2, steps = 50)
```

# 10 Species Pre-Processing of Images

```{r}
train_10_dir <- file.path(base_dir, "train_10")
validation_10_dir <- file.path(base_dir, "validation_10")
test_10_dir <- file.path(base_dir, "test_10")

dir.create(train_10_dir)
dir.create(validation_10_dir)
dir.create(test_10_dir)

#create folder for each species
for (i in 1:length(species_10)){
  dir.create(file.path(train_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
  dir.create(file.path(validation_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
  dir.create(file.path(test_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
}
```

```{r}
# create test, validation, and training groups of images for 10 species
for(i in 1:length(species_10)){
  # create 5 groups of 10 random samples
  species_samples_10 <- replicate(5, 
                                  sample(list.files(paste0(dir_train_mini, "/", species_10[[i]]), 
                                                    full.names = TRUE), replace = FALSE, 10))
  ## train n = 30 ##
  train <- rbind(species_samples_10[,1], species_samples_10[,2], species_samples_10[,3])
  file.copy(from = train, 
            to = paste0(train_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## validation n = 10 ##
  validate <- species_samples_10[,4]
  file.copy(from = validate,
            to = paste0(validation_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## train n = 10 ##
  test <- species_samples_10[,5]
  file.copy(from = test,
            to = paste0(test_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
}
```

```{r}
test_datagen_10 <- image_data_generator(rescale = 1/255)
train_datagen_10 <- image_data_generator(rescale = 1/255)
validation_datagen_10 <- image_data_generator(rescale = 1/255)
```

```{r}
train_generator_10 <- flow_images_from_directory(
  # This is the target directory
  train_10_dir,
  # This is the data generator
  train_datagen_10,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 5,
  # change label to categorical 
  class_mode = "categorical")
```

```{r}
validation_generator_10 <- flow_images_from_directory(
  validation_10_dir,
  validation_datagen_10,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "categorical")
```

```{r}
batch <- generator_next(train_generator_10)
str(batch)
```

# Apply Images to Multi-Class Classification Deep Learning Models 

## Multi-Class Classification: Neural Net

3. **10 Species (multi-class classification) - neural net**.  Draw from [3.5 📰 Newswires (multi-class classification)](./lab4b_examples.html).

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_flatten() %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "softmax")

model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
```

```{r}
history_3 <- model %>% fit(
  train_generator_10,
  steps_per_epoch = 5,
  epochs = 30,
  validation_data = validation_generator_10,
  validation_steps = 5)
```

```{r}
history_3
```

```{r}
test_generator_3 <- flow_images_from_directory(
  test_10_dir,
  test_datagen_10,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
model %>% evaluate(test_generator_3, steps = 50)
```

## Multi-Class Classification: Convolutional Neural Net

4. **10 Species (multi-class classification) - convolutional neural net**. Draw from [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html) and update necessary values to go from binary to mult-class classification.

```{r}
# make the new model  
model <- keras_model_sequential() %>% 
  layer_conv_2d(
    filters = 32, kernel_size = c(3, 3), activation = "relu",
    input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")  
  
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc"))
```

```{r}
history_3 <- model %>% fit(
    train_generator_10,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator_10,
    validation_steps = 5)
```

```{r}
history_3
```

```{r}
test_generator_4 <- flow_images_from_directory(
  test_10_dir,
  test_datagen_10,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
model %>% evaluate(test_generator_4, steps = 50)
```

In your models, be sure to include the following:

- Split the original images per species (n=50) into train (n=30), validate (n=10) and test (n=10). These are almost absurdly few files to feed into these complex deep learning models but will serve as a good learning example.

- Include accuracy metric and validation in the fitting process and history plot.

- Evaluate loss and accuracy on your test model results. Compare standard neural network and convolutional neural network results.
